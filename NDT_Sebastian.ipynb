{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import exercises.tools.utils as utils\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from IPython.display import display, Math, Latex, Markdown, HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 143949 data points from map.pcd\n"
     ]
    }
   ],
   "source": [
    "map_cloud = o3d.io.read_point_cloud(\"app/dataset/map.pcd\") #projects/dataset/map.pcd\n",
    "\n",
    "# Print the number of points in the map cloud\n",
    "print(f\"Loaded {len(map_cloud.points)} data points from map.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = \"app/dataset/frames\"\n",
    "frame_files = os.listdir(frames_dir)\n",
    "frames = [o3d.io.read_point_cloud(os.path.join(frames_dir, f)) for f in frame_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29560711 -0.48462959 -0.79555747]\n"
     ]
    }
   ],
   "source": [
    "print(frames[0].get_center())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize registration\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "draw_registration_result(map_cloud, frames[0], trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=6.946905e-06, inlier_rmse=2.677878e-03, and correspondence_set size of 1\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    map_cloud, frames[0], threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled C++ library was not found in the current directory. Please use `load_library` to load it from a custom directory, then ignore this message.\n"
     ]
    }
   ],
   "source": [
    "#lib wrapper for cpp registration libary from: https://github.com/hummat/registration\n",
    "import os\n",
    "import ctypes\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_library(path: str = os.getcwd(), name: str = \"libregistration_pcl110\") -> None:\n",
    "    global REGLIB\n",
    "    try:\n",
    "        REGLIB = np.ctypeslib.load_library(libname=name, loader_path=path)\n",
    "        print(REGLIB)\n",
    "    except OSError:\n",
    "        print(\"Compiled C++ library was not found in the current directory. Please use `load_library` to load it from \"\n",
    "              \"a custom directory, then ignore this message.\")\n",
    "\n",
    "\n",
    "load_library()\n",
    "\n",
    "\n",
    "def load_data(path: str, delimiter: str = ' ') -> np.ndarray:\n",
    "    \"\"\"Loads point cloud data of type `CSV`, `PLY` and `PCD`.\n",
    "\n",
    "    The file should contain one point per line where each number is separated by the `delimiter` character.\n",
    "    Any none numeric lines will be skipped.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the file.\n",
    "        delimiter (char): Separation of numbers in each line of the file.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray of shape NxD where `N` are the number of points in the point cloud and `D` their dimension.\n",
    "    \"\"\"\n",
    "    data = list()\n",
    "    with open(path, newline='\\n') as file:\n",
    "        reader = csv.reader(file, delimiter=delimiter, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        lines = 0\n",
    "        skips = 0\n",
    "        while True:\n",
    "            try:\n",
    "                row = next(reader)\n",
    "                row = [x for x in row if not isinstance(x, str)]\n",
    "                if len(row) in [3, 6, 9]:\n",
    "                    data.append(row[:3])\n",
    "                else:\n",
    "                    skips += 1\n",
    "            except ValueError:\n",
    "                skips += 1\n",
    "                pass\n",
    "            except StopIteration:\n",
    "                print(f\"Found {lines} lines. Skipped {skips}. Loaded {lines - skips} points.\")\n",
    "                break\n",
    "            lines += 1\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def set_argtypes(algorithm, source, target):\n",
    "    \"\"\"Tells the underlying C++ code which data types and dimensions to expect.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str): The registration algorithm to use. One of `icp` or `ndt`.\n",
    "        source (ndarray): The source point cloud.\n",
    "        target (ndarray): The target point cloud.\n",
    "    \"\"\"\n",
    "    REGLIB.icp.restype = ctypes.c_double\n",
    "    REGLIB.ndt.restype = ctypes.c_double\n",
    "    argtypes = [np.ctypeslib.ndpointer(dtype=np.float64, ndim=source.ndim, shape=source.shape,\n",
    "                                       flags='C_CONTIGUOUS'), ctypes.c_size_t,\n",
    "                np.ctypeslib.ndpointer(dtype=np.float64, ndim=target.ndim, shape=target.shape,\n",
    "                                       flags='C_CONTIGUOUS'), ctypes.c_size_t,\n",
    "                np.ctypeslib.ndpointer(dtype=np.float64, ndim=2, shape=(4, 4), flags='C_CONTIGUOUS'),\n",
    "                ctypes.c_int, ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_bool]\n",
    "    if algorithm == 'icp':\n",
    "        REGLIB.icp.argtypes = argtypes\n",
    "    elif algorithm == 'ndt':\n",
    "        argtypes.extend([ctypes.c_float, ctypes.c_double, ctypes.c_float])\n",
    "        REGLIB.ndt.argtypes = argtypes\n",
    "\n",
    "\n",
    "def icp(source,\n",
    "        target,\n",
    "        nr_iterations=25,\n",
    "        distance_threshold=1.0,\n",
    "        epsilon=0.01,\n",
    "        inlier_threshold=0.05,\n",
    "        downsample=0,\n",
    "        visualize=False):\n",
    "    \"\"\"The `Iterative Closest Point` (ICP) algorithm.\n",
    "\n",
    "    Args:\n",
    "        source (ndarray): The point cloud that we want to align to the target.\n",
    "        target (ndarray): The point cloud that the source is aligned to.\n",
    "        nr_iterations (int): The maximum number of iterations the internal optimization should run for.\n",
    "        distance_threshold (float): The maximum distance threshold between two correspondent points in\n",
    "                                    source -> target. If the distance is larger than this threshold, the points will\n",
    "                                    be ignored in the alignment process.\n",
    "        epsilon (float): The transformation epsilon (maximum allowable difference between two consecutive\n",
    "                 transformations) in order for an optimization to be considered as having converged to the final\n",
    "                 solution.\n",
    "        inlier_threshold (float): The inlier distance threshold for the internal RANSAC outlier rejection loop.\n",
    "                          The method considers a point to be an inlier, if the distance between the target data\n",
    "                          index and the transformed source index is smaller than the given inlier distance\n",
    "                          threshold.\n",
    "        downsample (float): Assembles a local 3D grid over a given PointCloud and downsamples + filters the data.\n",
    "        visualize (bool): Can be used to visualize and control the progress of the algorithm.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray with the final transformation matrix between source and target.\n",
    "    \"\"\"\n",
    "\n",
    "    transformation = np.identity(4)\n",
    "    set_argtypes('icp', source, target)\n",
    "    score = REGLIB.icp(source, len(source), target, len(target), transformation,\n",
    "                       nr_iterations, distance_threshold, epsilon, inlier_threshold, downsample, visualize)\n",
    "    print(f\"ICP converged. Fitness score: {score:.2f}\") if score > 0 else print(\"ICP did not converge!\")\n",
    "    return transformation\n",
    "\n",
    "\n",
    "def ndt(source,\n",
    "        target,\n",
    "        nr_iterations=25,\n",
    "        distance_threshold=1.0,\n",
    "        epsilon=0.01,\n",
    "        inlier_threshold=0.05,\n",
    "        downsample=0,\n",
    "        visualize=False,\n",
    "        resolution=1.0,\n",
    "        step_size=0.1,\n",
    "        voxelize=0):\n",
    "    \"\"\"The `Normal Distributions Transform` (NDT) algorithm.\n",
    "\n",
    "    Args:\n",
    "        source (ndarray): The point cloud that we want to align to the target.\n",
    "        target (ndarray): The point cloud that the source is aligned to.\n",
    "        nr_iterations (int): The maximum number of iterations the internal optimization should run for.\n",
    "        distance_threshold (float): The maximum distance threshold between two correspondent points in\n",
    "                                    source -> target. If the distance is larger than this threshold, the points will\n",
    "                                    be ignored in the alignment process.\n",
    "        epsilon (float): The transformation epsilon (maximum allowable difference between two consecutive\n",
    "                 transformations) in order for an optimization to be considered as having converged to the final\n",
    "                 solution.\n",
    "        inlier_threshold (float): The inlier distance threshold for the internal RANSAC outlier rejection loop.\n",
    "                          The method considers a point to be an inlier, if the distance between the target data\n",
    "                          index and the transformed source index is smaller than the given inlier distance\n",
    "                          threshold.\n",
    "        downsample (float): Assembles a local 3D grid over a given PointCloud and downsamples + filters the data.\n",
    "        visualize (bool): Can be used to visualize and control the progress of the algorithm.\n",
    "        resolution (float): The resolution of the voxel grid. Try increasing this in case of core dumps.\n",
    "        step_size (float): The Newton line search maximum step length.\n",
    "        voxelize (bool): If set to `True`, the source cloud is converted into a voxel model before alignment.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray with the final transformation matrix between source and target.\n",
    "    \"\"\"\n",
    "\n",
    "    transformation = np.identity(4)\n",
    "    set_argtypes('ndt', source, target)\n",
    "    score = REGLIB.ndt(source, len(source), target, len(target), transformation,\n",
    "                  nr_iterations, distance_threshold, epsilon, inlier_threshold, downsample, visualize,\n",
    "                  resolution, step_size, voxelize)\n",
    "    print(f\"NDT converged. Fitness score: {score:.2f}\") if score > 0 else print(\"NDT did not converge!\")\n",
    "    return transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22369 lines. Skipped 11. Loaded 22358 points.\n",
      "Found 143960 lines. Skipped 11. Loaded 143949 points.\n",
      "<CDLL '/app/libregistration_pcl110.so', handle 1035ffa0 at 0x7f08e371f9a0>\n",
      "NDT converged. Fitness score: 0.04\n",
      "Runtime: 129.18612122535706\n",
      "[[ 9.99998927e-01 -1.14443805e-03  9.44722851e-04  8.39681830e-04]\n",
      " [ 1.14385341e-03  9.99999166e-01  6.19078171e-04  1.50578637e-02]\n",
      " [-9.45430540e-04 -6.17996848e-04  9.99999404e-01 -9.88431573e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "    # Only needed if you want to use manually compiled library code\n",
    "    # reglib.load_library(os.path.join(os.curdir, \"cmake-build-debug\"))\n",
    "\n",
    "    # Load you data)\n",
    "source_points = load_data(\"app/dataset/frames/frame_1.pcd\")\n",
    "target_points = load_data(\"app/dataset/map.pcd\")\n",
    "\n",
    "    # Run the registration algorithm\n",
    "start = time.time()\n",
    "load_library(\"app/libregistration_pcl110.so\")\n",
    "trans = ndt(source=source_points, target=target_points, nr_iterations=1, epsilon=0.01,\n",
    "                       inlier_threshold=0.05, distance_threshold=5.0, downsample=0, visualize=True)\n",
    "                       #resolution=12.0, step_size=0.5, voxelize=0)\n",
    "print(\"Runtime:\", time.time() - start)\n",
    "print(trans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
