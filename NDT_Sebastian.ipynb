{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import exercises.tools.utils as utils\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from IPython.display import display, Math, Latex, Markdown, HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = \"app/dataset/frames\"\n",
    "frame_files = os.listdir(frames_dir)\n",
    "#frames = [o3d.io.read_point_cloud(os.path.join(frames_dir, f)) for f in frame_files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDT\n",
    "\n",
    "The normal distribution transform divides the pointcloud map into a grid. It calculates the probability densitiy function based on the normal distribution for the points to estimatate how likely is is, that a point belongs into certain grid cell. To optimize this function the newton algorithm is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled C++ library was not found in the current directory. Please use `load_library` to load it from a custom directory, then ignore this message.\n"
     ]
    }
   ],
   "source": [
    "#lib wrapper for cpp registration libary slightly altered from: https://github.com/hummat/registration\n",
    "#using registration library pcl110\n",
    "import os\n",
    "import ctypes\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_library(path: str = os.getcwd(), name: str = \"libregistration_pcl110\") -> None:\n",
    "    global REGLIB\n",
    "    try:\n",
    "        REGLIB = np.ctypeslib.load_library(libname=name, loader_path=path)\n",
    "        print(REGLIB)\n",
    "    except OSError:\n",
    "        print(\"Compiled C++ library was not found in the current directory. Please use `load_library` to load it from \"\n",
    "              \"a custom directory, then ignore this message.\")\n",
    "\n",
    "\n",
    "load_library()\n",
    "\n",
    "\n",
    "def load_data(path: str, delimiter: str = ' ') -> np.ndarray:\n",
    "    \"\"\"Loads point cloud data of type `CSV`, `PLY` and `PCD`.\n",
    "\n",
    "    The file should contain one point per line where each number is separated by the `delimiter` character.\n",
    "    Any none numeric lines will be skipped.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the file.\n",
    "        delimiter (char): Separation of numbers in each line of the file.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray of shape NxD where `N` are the number of points in the point cloud and `D` their dimension.\n",
    "    \"\"\"\n",
    "    data = list()\n",
    "    with open(path, newline='\\n') as file:\n",
    "        reader = csv.reader(file, delimiter=delimiter, quoting=csv.QUOTE_NONNUMERIC)\n",
    "        lines = 0\n",
    "        skips = 0\n",
    "        while True:\n",
    "            try:\n",
    "                row = next(reader)\n",
    "                row = [x for x in row if not isinstance(x, str)]\n",
    "                if len(row) in [3, 6, 9]:\n",
    "                    data.append(row[:3])\n",
    "                else:\n",
    "                    skips += 1\n",
    "            except ValueError:\n",
    "                skips += 1\n",
    "                pass\n",
    "            except StopIteration:\n",
    "                print(f\"Found {lines} lines. Skipped {skips}. Loaded {lines - skips} points.\")\n",
    "                break\n",
    "            lines += 1\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def set_argtypes(algorithm, source, target):\n",
    "    \"\"\"Tells the underlying C++ code which data types and dimensions to expect.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str): The registration algorithm to use. One of `icp` or `ndt`.\n",
    "        source (ndarray): The source point cloud.\n",
    "        target (ndarray): The target point cloud.\n",
    "    \"\"\"\n",
    "    REGLIB.icp.restype = ctypes.c_double\n",
    "    REGLIB.ndt.restype = ctypes.c_double\n",
    "    argtypes = [np.ctypeslib.ndpointer(dtype=np.float64, ndim=source.ndim, shape=source.shape,\n",
    "                                       flags='C_CONTIGUOUS'), ctypes.c_size_t,\n",
    "                np.ctypeslib.ndpointer(dtype=np.float64, ndim=target.ndim, shape=target.shape,\n",
    "                                       flags='C_CONTIGUOUS'), ctypes.c_size_t,\n",
    "                np.ctypeslib.ndpointer(dtype=np.float64, ndim=2, shape=(4, 4), flags='C_CONTIGUOUS'),\n",
    "                ctypes.c_int, ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_bool]\n",
    "    if algorithm == 'icp':\n",
    "        REGLIB.icp.argtypes = argtypes\n",
    "    elif algorithm == 'ndt':\n",
    "        argtypes.extend([ctypes.c_float, ctypes.c_double, ctypes.c_float])\n",
    "        REGLIB.ndt.argtypes = argtypes\n",
    "\n",
    "\n",
    "def icp(source,\n",
    "        target,\n",
    "        nr_iterations=25,\n",
    "        distance_threshold=1.0,\n",
    "        epsilon=0.01,\n",
    "        inlier_threshold=0.05,\n",
    "        downsample=0,\n",
    "        visualize=False):\n",
    "    \"\"\"The `Iterative Closest Point` (ICP) algorithm.\n",
    "\n",
    "    Args:\n",
    "        source (ndarray): The point cloud that we want to align to the target.\n",
    "        target (ndarray): The point cloud that the source is aligned to.\n",
    "        nr_iterations (int): The maximum number of iterations the internal optimization should run for.\n",
    "        distance_threshold (float): The maximum distance threshold between two correspondent points in\n",
    "                                    source -> target. If the distance is larger than this threshold, the points will\n",
    "                                    be ignored in the alignment process.\n",
    "        epsilon (float): The transformation epsilon (maximum allowable difference between two consecutive\n",
    "                 transformations) in order for an optimization to be considered as having converged to the final\n",
    "                 solution.\n",
    "        inlier_threshold (float): The inlier distance threshold for the internal RANSAC outlier rejection loop.\n",
    "                          The method considers a point to be an inlier, if the distance between the target data\n",
    "                          index and the transformed source index is smaller than the given inlier distance\n",
    "                          threshold.\n",
    "        downsample (float): Assembles a local 3D grid over a given PointCloud and downsamples + filters the data.\n",
    "        visualize (bool): Can be used to visualize and control the progress of the algorithm.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray with the final transformation matrix between source and target.\n",
    "    \"\"\"\n",
    "\n",
    "    transformation = np.identity(4)\n",
    "    set_argtypes('icp', source, target)\n",
    "    score = REGLIB.icp(source, len(source), target, len(target), transformation,\n",
    "                       nr_iterations, distance_threshold, epsilon, inlier_threshold, downsample, visualize)\n",
    "    print(f\"ICP converged. Fitness score: {score:.2f}\") if score > 0 else print(\"ICP did not converge!\")\n",
    "    return transformation\n",
    "\n",
    "\n",
    "def ndt(source,\n",
    "        target,\n",
    "        nr_iterations=25,\n",
    "        distance_threshold=1.0,\n",
    "        epsilon=0.01,\n",
    "        inlier_threshold=0.05,\n",
    "        downsample=0,\n",
    "        visualize=False,\n",
    "        resolution=1.0,\n",
    "        step_size=0.1,\n",
    "        voxelize=0):\n",
    "    \"\"\"The `Normal Distributions Transform` (NDT) algorithm.\n",
    "\n",
    "    Args:\n",
    "        source (ndarray): The point cloud that we want to align to the target.\n",
    "        target (ndarray): The point cloud that the source is aligned to.\n",
    "        nr_iterations (int): The maximum number of iterations the internal optimization should run for.\n",
    "        distance_threshold (float): The maximum distance threshold between two correspondent points in\n",
    "                                    source -> target. If the distance is larger than this threshold, the points will\n",
    "                                    be ignored in the alignment process.\n",
    "        epsilon (float): The transformation epsilon (maximum allowable difference between two consecutive\n",
    "                 transformations) in order for an optimization to be considered as having converged to the final\n",
    "                 solution.\n",
    "        inlier_threshold (float): The inlier distance threshold for the internal RANSAC outlier rejection loop.\n",
    "                          The method considers a point to be an inlier, if the distance between the target data\n",
    "                          index and the transformed source index is smaller than the given inlier distance\n",
    "                          threshold.\n",
    "        downsample (float): Assembles a local 3D grid over a given PointCloud and downsamples + filters the data.\n",
    "        visualize (bool): Can be used to visualize and control the progress of the algorithm.\n",
    "        resolution (float): The resolution of the voxel grid. Try increasing this in case of core dumps.\n",
    "        step_size (float): The Newton line search maximum step length.\n",
    "        voxelize (bool): If set to `True`, the source cloud is converted into a voxel model before alignment.\n",
    "\n",
    "    Returns:\n",
    "        A ndarray with the final transformation matrix between source and target.\n",
    "    \"\"\"\n",
    "\n",
    "    transformation = np.identity(4)\n",
    "    set_argtypes('ndt', source, target)\n",
    "    score = REGLIB.ndt(source, len(source), target, len(target), transformation,\n",
    "                  nr_iterations, distance_threshold, epsilon, inlier_threshold, downsample, visualize,\n",
    "                  resolution, step_size, voxelize)\n",
    "    #print(f\"NDT converged. Fitness score: {score:.2f}\") if score > 0 else print(\"NDT did not converge!\")\n",
    "    return transformation, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CDLL '/app/libregistration_pcl110.so', handle 58c95c0 at 0x7f32485bda00>\n",
      "Found 143960 lines. Skipped 11. Loaded 143949 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9104 lines. Skipped 11. Loaded 9093 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:07,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22369 lines. Skipped 11. Loaded 22358 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13580 lines. Skipped 11. Loaded 13569 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14875 lines. Skipped 11. Loaded 14864 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:02,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13437 lines. Skipped 11. Loaded 13426 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:03<00:01,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12078 lines. Skipped 11. Loaded 12067 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:04<00:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12213 lines. Skipped 11. Loaded 12202 points.\n",
      "Found 10780 lines. Skipped 11. Loaded 10769 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11521 lines. Skipped 11. Loaded 11510 points.\n",
      "Found 11323 lines. Skipped 11. Loaded 11312 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "load_library(\"app/libregistration_pcl18.so\")\n",
    "target_points = load_data(\"app/dataset/map.pcd\")\n",
    "transformation_list = []\n",
    "score_lst = []\n",
    "samples = 10\n",
    "\n",
    "#loops over all frames and returns the ndt transformation matrices and the core calculated by the cpp library\n",
    "for sample in tqdm(range(samples)):\n",
    "\n",
    "    frame_path = os.path.join(\"app/dataset/frames/\", frame_files[sample])\n",
    "    source_points = load_data(frame_path)\n",
    "    if sample == 9:\n",
    "        trans, score = ndt(source=source_points, target=target_points, nr_iterations=1, epsilon=0.001,\n",
    "                            inlier_threshold=0.05, distance_threshold=0.5, downsample=0.5, visualize=True,\n",
    "                            voxelize=0.2)\n",
    "    else:\n",
    "        trans, score = ndt(source=source_points, target=target_points, nr_iterations=1, epsilon=0.001,\n",
    "                            inlier_threshold=0.05, distance_threshold=0.5, downsample=0.5, visualize=False,\n",
    "                            voxelize=0.2)\n",
    "\n",
    "    transformation_list.append(trans)\n",
    "    score_lst.append(score)\n",
    "\n",
    "#print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score: 4.129611116293453\n",
      "[[ 0.99979305 -0.00194124  0.02024991  0.0383251 ]\n",
      " [ 0.00236185  0.99978149 -0.02076747 -0.06870046]\n",
      " [-0.02020516  0.020811    0.99957925  0.0544612 ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Score: {sum(score_lst)/len(score_lst)}')\n",
    "print(transformation_list[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
