{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#load ground truth csc as pandas dataframe\n",
    "g_df = pd.read_csv(\"/app/dataset/ground_truth.csv\")\n",
    "\n",
    "#load input frames (source)\n",
    "frames_dir = \"/app/dataset/frames\"\n",
    "frame_files = os.listdir(frames_dir)\n",
    "#frames = [o3d.io.read_point_cloud(os.path.join(frames_dir, f)) for f in frame_files]\n",
    "\n",
    "#load target map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP Localization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "initTransform = np.identity(4)\n",
    "for i, frame in enumerate(frames):\n",
    "    # Downsample the point cloud using a voxel grid filter\n",
    "\n",
    "\n",
    "    frame_cloud_downsampled = frame.voxel_down_sample(voxel_size = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "    source = copy.deepcopy(frame_cloud_downsampled)\n",
    "    target = copy.deepcopy(map_cloud)\n",
    "\n",
    "    # Filter points with z-axis values less than 1\n",
    "    #source = source.transform(initTransform)\n",
    "    \n",
    "    points = np.asarray(source.points)\n",
    "# Apply the transformation matrix to the point\n",
    "\n",
    "#To transform a 3D points array using a 4x4 transformation matrix in Python, you can use the NumPy library. Here's an example code that shows how to do it:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Transform the 3D points by multiplying them with the transformation matrix\n",
    "    # Add an extra row of 1s to the points array to make it homogeneous\n",
    "    homogeneous_points = np.hstack([points, np.ones((points.shape[0], 1))])\n",
    "    transformed_homogeneous_points = np.dot(initTransform, homogeneous_points.T).T\n",
    "\n",
    "    # Divide the x, y, and z coordinates by the last column to remove the homogeneous coordinate\n",
    "    transformed_points = transformed_homogeneous_points[:, :3] / transformed_homogeneous_points[:, 3:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_points = transformed_points[transformed_points[:, 2] > 1]\n",
    "    # Convert back to open3d point cloud\n",
    "    filtered_pcd = o3d.geometry.PointCloud()\n",
    "    filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    #trans_init = np.identity(4)\n",
    "    threshold = 1\n",
    " \n",
    "    reg_result = o3d.pipelines.registration.registration_icp(filtered_pcd, target, threshold)\n",
    "\n",
    "    initTransform = reg_result.transformation * initTransform\n",
    "\n",
    "\n",
    "    \n",
    "    frame_gt = g_df[g_df['Frame'] == i]\n",
    "\n",
    "    \n",
    "# Calculate L2 norm \n",
    "    errors = np.linalg.norm(np.array([initTransform[0,3],initTransform[1,3],initTransform[2,3]])-np.array([ frame_gt[' x'].item(),  frame_gt[' y'].item(),  frame_gt[' z'].item()]))   \n",
    "\n",
    "    print('Frame :', i)\n",
    "    print(\"Errors--------:\", errors)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {total_time:.3f} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the map from the map.pcd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 143949 data points from map.pcd\n"
     ]
    }
   ],
   "source": [
    "map_cloud = o3d.io.read_point_cloud(\"/app/dataset/map.pcd\") #projects/dataset/map.pcd\n",
    "\n",
    "# Print the number of points in the map cloud\n",
    "print(f\"Loaded {len(map_cloud.points)} data points from map.pcd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteritatively go through each frame and localize the car in the given map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m frames_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/app/dataset/frames\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m frame_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(frames_dir)\n\u001b[0;32m----> 3\u001b[0m frames \u001b[39m=\u001b[39m [o3d\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_point_cloud(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(frames_dir, f)) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m frame_files[:\u001b[39m500\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[81], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m frames_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/app/dataset/frames\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m frame_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(frames_dir)\n\u001b[0;32m----> 3\u001b[0m frames \u001b[39m=\u001b[39m [o3d\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_point_cloud(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(frames_dir, f)) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m frame_files[:\u001b[39m500\u001b[39m]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frames_dir = \"/app/dataset/frames\"\n",
    "frame_files = os.listdir(frames_dir)\n",
    "frames = [o3d.io.read_point_cloud(os.path.join(frames_dir, f)) for f in frame_files[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29560711 -0.48462959 -0.79555747]\n"
     ]
    }
   ],
   "source": [
    "print(frames[0].get_center())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.02\n",
    "trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n",
    "                         [-0.139, 0.967, -0.215, 0.7],\n",
    "                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "#draw_registration_result(map_cloud, frames[0], trans_init)  #does not work, because i forgot to start Xlauncher first, lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=6.946905e-06, inlier_rmse=2.677878e-03, and correspondence_set size of 1\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    map_cloud, frames[0], threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=6.946905e-06, inlier_rmse=0.000000e+00, and correspondence_set size of 1\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.862       0.011      -0.507       0.50254853]\n",
      " [-0.139       0.967      -0.215       0.69950987]\n",
      " [ 0.487       0.255       0.835      -1.39933986]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    map_cloud, frames[0], threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "#draw_registration_result(map_cloud, frames[0], reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 0.2\n",
    "icp_params = o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100)\n",
    "icp_params.relative_fitness = 1e-6\n",
    "icp_params.relative_rmse = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it on 1 frame\n",
    "frame_cloud = frames[0].voxel_down_sample( voxel_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07772482, -1.00245112, -0.7023499 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.get_center()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pose:\n",
    "    def __init__(self, point, rotate):\n",
    "        self.point = point\n",
    "        self.rotate = rotate\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class Rotate:\n",
    "    def __init__(self, roll, pitch, yaw):\n",
    "        self.roll = roll\n",
    "        self.pitch = pitch\n",
    "        self.yaw = yaw\n",
    "\n",
    "def getPose(matrix):\n",
    "    pose_point = Point(matrix[0,3], matrix[1,3], matrix[2,3])\n",
    "    pose_rotate = Rotate(np.arctan2(matrix[1, 0], matrix[0, 0]), np.arctan2(-matrix[2,0], np.sqrt(matrix[2,1]**2 + matrix[2,2]**2)), np.arctan2(matrix[2,1], matrix[2,2]))\n",
    "    pose = Pose(pose_point, pose_rotate)\n",
    "    return pose\n",
    "\n",
    "\n",
    "def transform3D(yaw, pitch, roll, xt, yt, zt):\n",
    "    matrix = np.identity(4)\n",
    "\n",
    "    matrix[0, 3] = xt\n",
    "    matrix[1, 3] = yt\n",
    "    matrix[2, 3] = zt\n",
    "\n",
    "    matrix[0, 0] = np.cos(yaw) * np.cos(pitch)\n",
    "    matrix[0, 1] = np.cos(yaw) * np.sin(pitch) * np.sin(roll) - np.sin(yaw) * np.cos(roll)\n",
    "    matrix[0, 2] = np.cos(yaw) * np.sin(pitch) * np.cos(roll) + np.sin(yaw) * np.sin(roll)\n",
    "    matrix[1, 0] = np.sin(yaw) * np.cos(pitch)\n",
    "    matrix[1, 1] = np.sin(yaw) * np.sin(pitch) * np.sin(roll) + np.cos(yaw) * np.cos(roll)\n",
    "    matrix[1, 2] = np.sin(yaw) * np.sin(pitch) * np.cos(roll) - np.cos(yaw) * np.sin(roll)\n",
    "    matrix[2, 0] = -np.sin(pitch)\n",
    "    matrix[2, 1] = np.cos(pitch) * np.sin(roll)\n",
    "    matrix[2, 2] = np.cos(pitch) * np.cos(roll)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_vector_to_affine(x):\n",
    "    # Extract translation and rotation values\n",
    "    tx, ty, tz, roll, pitch, yaw = x\n",
    "\n",
    "    # Create rotation matrix from roll, pitch, yaw angles\n",
    "    cr = np.cos(roll)\n",
    "    sr = np.sin(roll)\n",
    "    cp = np.cos(pitch)\n",
    "    sp = np.sin(pitch)\n",
    "    cy = np.cos(yaw)\n",
    "    sy = np.sin(yaw)\n",
    "\n",
    "    rotation_matrix = np.array([\n",
    "        [cp*cy, cp*sy, -sp],\n",
    "        [sr*sp*cy - cr*sy, sr*sp*sy + cr*cy, sr*cp],\n",
    "        [cr*sp*cy + sr*sy, cr*sp*sy - sr*cy, cr*cp]\n",
    "    ])\n",
    "\n",
    "    # Create translation vector\n",
    "    translation_vector = np.array([tx, ty, tz])\n",
    "\n",
    "    # Combine rotation and translation to create affine transformation matrix\n",
    "    affine_transform = np.eye(4)\n",
    "    affine_transform[:3, :3] = rotation_matrix\n",
    "    affine_transform[:3, 3] = translation_vector\n",
    "\n",
    "    return affine_transform\n",
    "\n",
    "def rmse(T1, T2):\n",
    "    # Compute RMSE between two transformation matrices\n",
    "    diff = T1 - T2\n",
    "    sq_err = np.multiply(diff, diff)\n",
    "    mse = np.mean(sq_err)\n",
    "    return np.sqrt(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = frame_cloud_downsampled.transform(initTransform)\n",
    "points = np.asarray(transf.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "    points = np.asarray(map_cloud.points)\n",
    "    filtered_points = points[points[:, 2] > 1]\n",
    "    # Convert back to open3d point cloud\n",
    "    map_cloud = o3d.geometry.PointCloud()\n",
    "    map_cloud.points = o3d.utility.Vector3dVector(filtered_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 29196 points."
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame : 0\n",
      "Errors--------: 0.0\n",
      "Frame : 1\n",
      "Errors--------: 0.0156357\n",
      "Frame : 2\n",
      "Errors--------: 0.00584579\n",
      "Frame : 3\n",
      "Errors--------: 0.00562843\n",
      "Frame : 4\n",
      "Errors--------: 0.00562843\n",
      "Frame : 5\n",
      "Errors--------: 0.00562843\n",
      "Frame : 6\n",
      "Errors--------: 0.00562843\n",
      "Frame : 7\n",
      "Errors--------: 0.00562843\n",
      "Frame : 8\n",
      "Errors--------: 0.00562843\n",
      "Frame : 9\n",
      "Errors--------: 0.00562843\n",
      "Frame : 10\n",
      "Errors--------: 0.00562843\n",
      "Frame : 11\n",
      "Errors--------: 0.00562843\n",
      "Frame : 12\n",
      "Errors--------: 0.00591316\n",
      "Frame : 13\n",
      "Errors--------: 0.00677673\n",
      "Frame : 14\n",
      "Errors--------: 0.00704376\n",
      "Frame : 15\n",
      "Errors--------: 0.00710373\n",
      "Frame : 16\n",
      "Errors--------: 0.007099\n",
      "Frame : 17\n",
      "Errors--------: 0.00697754\n",
      "Frame : 18\n",
      "Errors--------: 0.00698051\n",
      "Frame : 19\n",
      "Errors--------: 0.00700378\n",
      "Frame : 20\n",
      "Errors--------: 0.00701149\n",
      "Frame : 21\n",
      "Errors--------: 0.00707542\n",
      "Frame : 22\n",
      "Errors--------: 0.00705162\n",
      "Frame : 23\n",
      "Errors--------: 0.00704933\n",
      "Frame : 24\n",
      "Errors--------: 0.00705543\n",
      "Frame : 25\n",
      "Errors--------: 0.0608321398169042\n",
      "Frame : 26\n",
      "Errors--------: 0.16085369237748726\n",
      "Frame : 27\n",
      "Errors--------: 0.37071139833925865\n",
      "Frame : 28\n",
      "Errors--------: 0.5465612099923252\n",
      "Frame : 29\n",
      "Errors--------: 0.7077795024311312\n",
      "Frame : 30\n",
      "Errors--------: 0.8787155626455383\n",
      "Frame : 31\n",
      "Errors--------: 1.05289554503871\n",
      "Frame : 32\n",
      "Errors--------: 1.2391643388300968\n",
      "Frame : 33\n",
      "Errors--------: 1.4011653161967825\n",
      "Frame : 34\n",
      "Errors--------: 1.5639913647478372\n",
      "Frame : 35\n",
      "Errors--------: 1.7537060657090435\n",
      "Frame : 36\n",
      "Errors--------: 1.9627701806703775\n",
      "Frame : 37\n",
      "Errors--------: 2.20548231776422\n",
      "Frame : 38\n",
      "Errors--------: 2.3388237347274368\n",
      "Frame : 39\n",
      "Errors--------: 2.5121298054519414\n",
      "Frame : 40\n",
      "Errors--------: 2.6501719954953398\n",
      "Frame : 41\n",
      "Errors--------: 2.7705437958555637\n",
      "Frame : 42\n",
      "Errors--------: 2.925247264589749\n",
      "Frame : 43\n",
      "Errors--------: 3.1099855549279183\n",
      "Frame : 44\n",
      "Errors--------: 3.2461170708621827\n",
      "Frame : 45\n",
      "Errors--------: 3.3624163658355486\n",
      "Frame : 46\n",
      "Errors--------: 3.602753456953752\n",
      "Frame : 47\n",
      "Errors--------: 3.7254028025741825\n",
      "Frame : 48\n",
      "Errors--------: 3.901322369645545\n",
      "Frame : 49\n",
      "Errors--------: 4.0795362017756185\n",
      "Frame : 50\n",
      "Errors--------: 4.283748875684065\n",
      "Frame : 51\n",
      "Errors--------: 4.444070371910891\n",
      "Frame : 52\n",
      "Errors--------: 4.589500227657929\n",
      "Frame : 53\n",
      "Errors--------: 4.763554396576636\n",
      "Frame : 54\n",
      "Errors--------: 4.902585120859394\n",
      "Frame : 55\n",
      "Errors--------: 5.058733935503184\n",
      "Frame : 56\n",
      "Errors--------: 5.2449326702806545\n",
      "Frame : 57\n",
      "Errors--------: 5.415118977868469\n",
      "Frame : 58\n",
      "Errors--------: 5.548129918187571\n",
      "Frame : 59\n",
      "Errors--------: 5.693764468569795\n",
      "Frame : 60\n",
      "Errors--------: 5.818690304589613\n",
      "Frame : 61\n",
      "Errors--------: 6.02742617470708\n",
      "Frame : 62\n",
      "Errors--------: 6.127393921558464\n",
      "Frame : 63\n",
      "Errors--------: 6.313705819571745\n",
      "Frame : 64\n",
      "Errors--------: 6.464216540194136\n",
      "Frame : 65\n",
      "Errors--------: 6.591803591971305\n",
      "Frame : 66\n",
      "Errors--------: 6.766581968860042\n",
      "Frame : 67\n",
      "Errors--------: 6.941980614366424\n",
      "Frame : 68\n",
      "Errors--------: 7.072298359437373\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[190], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m#trans_init = np.identity(4)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 47\u001b[0m reg_result \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39;49mpipelines\u001b[39m.\u001b[39;49mregistration\u001b[39m.\u001b[39;49mregistration_icp(filtered_pcd, target, threshold)\n\u001b[1;32m     49\u001b[0m initTransform \u001b[39m=\u001b[39m reg_result\u001b[39m.\u001b[39mtransformation \u001b[39m*\u001b[39m initTransform\n\u001b[1;32m     53\u001b[0m frame_gt \u001b[39m=\u001b[39m g_df[g_df[\u001b[39m'\u001b[39m\u001b[39mFrame\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "initTransform = np.identity(4)\n",
    "for i, frame in enumerate(frames):\n",
    "    # Downsample the point cloud using a voxel grid filter\n",
    "\n",
    "\n",
    "    frame_cloud_downsampled = frame.voxel_down_sample(voxel_size = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "    source = copy.deepcopy(frame_cloud_downsampled)\n",
    "    target = copy.deepcopy(map_cloud)\n",
    "\n",
    "    # Filter points with z-axis values less than 1\n",
    "    #source = source.transform(initTransform)\n",
    "    \n",
    "    points = np.asarray(source.points)\n",
    "# Apply the transformation matrix to the point\n",
    "\n",
    "#To transform a 3D points array using a 4x4 transformation matrix in Python, you can use the NumPy library. Here's an example code that shows how to do it:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Transform the 3D points by multiplying them with the transformation matrix\n",
    "    # Add an extra row of 1s to the points array to make it homogeneous\n",
    "    homogeneous_points = np.hstack([points, np.ones((points.shape[0], 1))])\n",
    "    transformed_homogeneous_points = np.dot(initTransform, homogeneous_points.T).T\n",
    "\n",
    "    # Divide the x, y, and z coordinates by the last column to remove the homogeneous coordinate\n",
    "    transformed_points = transformed_homogeneous_points[:, :3] / transformed_homogeneous_points[:, 3:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filtered_points = transformed_points[transformed_points[:, 2] > 1]\n",
    "    # Convert back to open3d point cloud\n",
    "    filtered_pcd = o3d.geometry.PointCloud()\n",
    "    filtered_pcd.points = o3d.utility.Vector3dVector(filtered_points)\n",
    "\n",
    "    #trans_init = np.identity(4)\n",
    "    threshold = 1\n",
    " \n",
    "    reg_result = o3d.pipelines.registration.registration_icp(filtered_pcd, target, threshold)\n",
    "\n",
    "    initTransform = reg_result.transformation * initTransform\n",
    "\n",
    "\n",
    "    \n",
    "    frame_gt = g_df[g_df['Frame'] == i]\n",
    "\n",
    "    \n",
    "# Calculate L2 norm \n",
    "    errors = np.linalg.norm(np.array([initTransform[0,3],initTransform[1,3],initTransform[2,3]])-np.array([ frame_gt[' x'].item(),  frame_gt[' y'].item(),  frame_gt[' z'].item()]))   \n",
    "\n",
    "    print('Frame :', i)\n",
    "    print(\"Errors--------:\", errors)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Total execution time: {total_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.610835   -3.4847713  -1.7901864]\n",
      " [ -1.7770556  -3.4030092  -1.7901864]\n",
      " [ -1.8586328  -3.3591485  -1.7901864]\n",
      " ...\n",
      " [  4.3966212 -21.229404   -1.6509889]\n",
      " [ -2.7634912  -6.3023229  -1.6377864]\n",
      " [ -2.6106298  -6.3671579  -1.6377864]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#To transform a 3D points array using a 4x4 transformation matrix in Python, you can use the NumPy library. Here's an example code that shows how to do it:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Transform the 3D points by multiplying them with the transformation matrix\n",
    "# Add an extra row of 1s to the points array to make it homogeneous\n",
    "homogeneous_points = np.hstack([points, np.ones((points.shape[0], 1))])\n",
    "transformed_homogeneous_points = np.dot(initTransform, homogeneous_points.T).T\n",
    "\n",
    "# Divide the x, y, and z coordinates by the last column to remove the homogeneous coordinate\n",
    "transformed_points = transformed_homogeneous_points[:, :3] / transformed_homogeneous_points[:, 3:]\n",
    "\n",
    "# Print the transformed points\n",
    "print(transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.610835   -3.4847713  -1.7901864]\n",
      " [ -1.7770556  -3.4030092  -1.7901864]\n",
      " [ -1.8586328  -3.3591485  -1.7901864]\n",
      " ...\n",
      " [  4.3966212 -21.229404   -1.6509889]\n",
      " [ -2.7634912  -6.3023229  -1.6377864]\n",
      " [ -2.6106298  -6.3671579  -1.6377864]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#To transform a 3D points array using a 4x4 transformation matrix in Python, you can use the NumPy library. Here's an example code that shows how to do it:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Transform the 3D points by multiplying them with the transformation matrix\n",
    "# Add an extra row of 1s to the points array to make it homogeneous\n",
    "homogeneous_points = np.hstack([points, np.ones((points.shape[0], 1))])\n",
    "transformed_homogeneous_points = np.dot(initTransform, homogeneous_points.T).T\n",
    "\n",
    "# Divide the x, y, and z coordinates by the last column to remove the homogeneous coordinate\n",
    "transformed_points = transformed_homogeneous_points[:, :3] / transformed_homogeneous_points[:, 3:]\n",
    "\n",
    "# Print the transformed points\n",
    "print(transformed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9268, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((initTransform[:3,:3] @ points.T).reshape(-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(initTransform[:3,:3] @ points.T).reshape(-1,3) +   initTransform[:3,3:].T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use performance measures to evaluate the localization effectiviness.\n",
    "\n",
    "Remember that to pass this task, the maximum lateral error cannot be bigger than 1.2 meters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the computing time (there is not a harsh requirement here, but should be analized.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
